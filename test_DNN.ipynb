{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-15 14:45:10.414176: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 378us/step\n",
      "     CHURCHMAN BIBLE f1_weigthted:0.376 | acc:0.418 | acc_adj:0.735\n",
      "16/16 [==============================] - 0s 366us/step\n",
      "      CROSS H CATTLE f1_weigthted:0.241 | acc:0.301 | acc_adj:0.804\n",
      "15/15 [==============================] - 0s 355us/step\n",
      "            LUKE G U f1_weigthted:0.336 | acc:0.319 | acc_adj:0.829\n",
      "15/15 [==============================] - 0s 352us/step\n",
      "               NEWBY f1_weigthted:0.449 | acc:0.432 | acc_adj:0.857\n",
      "13/13 [==============================] - 0s 414us/step\n",
      "               NOLAN f1_weigthted:0.451 | acc:0.429 | acc_adj:0.846\n",
      "3/3 [==============================] - 0s 666us/step\n",
      "          Recruit F9 f1_weigthted:0.921 | acc:0.853 | acc_adj:1.000\n",
      "15/15 [==============================] - 0s 342us/step\n",
      "             SHANKLE f1_weigthted:0.445 | acc:0.492 | acc_adj:0.944\n",
      "15/15 [==============================] - 0s 366us/step\n",
      "           SHRIMPLIN f1_weigthted:0.616 | acc:0.624 | acc_adj:0.941\n",
      "Avg F1 47.93021258378703 Avg Acc 48.36021322430841 Avg Adj 86.95350505192619\n",
      "Blind Well Test Run Time: 30.545861 seconds\n",
      "[0.42967543 0.46213293 0.49845201 0.39009288 0.45820433]\n",
      "Cross Validation Run Time: 4.054826 seconds\n",
      "101/101 [==============================] - 0s 298us/step\n",
      "f1 training error:  0.737422\n",
      "f1 test error:  47.930213\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------------------------------------------#\n",
    "import sys\n",
    "sys.path.append('./Libs') \n",
    "import functions as F\n",
    "#-----------------------------------------------------------------------------------------#\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "import time as tm\n",
    "import pandas as pd\n",
    "#-----------------------------------------------------------------------------------------#\n",
    "from scipy.signal import medfilt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#-----------------------------------------------------------------------------------------#\n",
    "\n",
    "'''\n",
    "step 1: import well-log data. For DL, the training data and the validation data are already split.\n",
    "'''\n",
    "\n",
    "# data = pd.read_csv('../reservoir_characteristics/datasets/well_logs.csv')\n",
    "training_data = pd.read_csv('../reservoir_characteristics/datasets/training_data.csv')\n",
    "blind_data = pd.read_csv('../reservoir_characteristics/datasets/nofacies_data.csv')\n",
    "\n",
    "'''\n",
    "step 2: prepare data for training, validation and test. DL trains data using the stratified method, which inputs data into neurons by well-log, not splitting by facies.\n",
    "\n",
    "This experiment will compare adjacent facies and facies.\n",
    "'''\n",
    "\n",
    "# NOTE define label colors and names\n",
    "facies_colors = ['#F4D03F', # Nonmarine sandstone\n",
    "                 '#F5B041', # Nonmarine coarse siltstone\n",
    "                 '#DC7633', # Nonmarine fine siltstone\n",
    "                 '#6E2C00', # Marine siltstone and shale\n",
    "                 '#1B4F72', # Mudstone (limestone)\n",
    "                 '#2E86C1', # Wackestone (limestone)\n",
    "                 '#AED6F1', # Dolomite\n",
    "                 '#A569BD', # Packstone-grainstone (limestone)\n",
    "                 '#196F3D'] # Phylloid-algal bafflestone (limestone)\n",
    "facies_labels = ['SS',\n",
    "                 'CSiS',\n",
    "                 'FSiS',\n",
    "                 'SiSh',\n",
    "                 'MS',\n",
    "                 'WS',\n",
    "                 'D',\n",
    "                 'PS',\n",
    "                 'BS']\n",
    "adjacent_facies = np.array([[1], [0, 2], [1], [4], [3, 5], [4, 6, 7], [5, 7], [5, 6, 8], [6, 7]])\n",
    "# NOTE assign facies colors \n",
    "facies_color_map = {}\n",
    "for ind, label in enumerate(facies_labels):\n",
    "    facies_color_map[label] = facies_colors[ind]\n",
    "# NOTE use a shortman of building function as lambda\n",
    "training_data.loc[:, 'FaciesLabels'] = training_data.apply(lambda row: F.label_facies(row, facies_labels), axis=1)\n",
    "# NOTE prepare data by well-log\n",
    "X = training_data.drop(['Formation', 'Well Name', 'Facies', 'FaciesLabels'], axis=1).values\n",
    "y = training_data['Facies'].values - 1\n",
    "X_blind = blind_data.drop(['Formation', 'Well Name'], axis=1).values\n",
    "wells = training_data['Well Name'].values\n",
    "\n",
    "'''\n",
    "step 3: normalized data\n",
    "'''\n",
    "\n",
    "scaler = preprocessing.RobustScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "'''\n",
    "step 4: loop training and evaluate the model well-by-well. This technique can help evaluate the inference in each well-log. Bear in mind that some well-logs contain less than nine facies.\n",
    "'''\n",
    "\n",
    "# NOTE preallocate memory for timing \n",
    "logo = LeaveOneGroupOut()\n",
    "t0 = tm.time()\n",
    "f1s_ls = []\n",
    "acc_ls = []\n",
    "adj_ls = []\n",
    "# NOTE begining loops\n",
    "for train, test in logo.split(X_scaled, y, groups=wells):\n",
    "    well_name = wells[test[0]]\n",
    "    X_tr = X_scaled[train]\n",
    "    X_te = X_scaled[test]\n",
    "    # NOTE convert y array into categories matrix\n",
    "    classes = 9\n",
    "    y_tr = np_utils.to_categorical(y[train], classes)\n",
    "    # NOTE  call neuron network\n",
    "    NN = F.DNN()\n",
    "    # NOTE training\n",
    "    NN.fit(X_tr, y_tr, epochs=15, batch_size=5, verbose=0) \n",
    "    # NOTE predict\n",
    "    y_hat = np.argmax(NN.predict(X_te), axis=-1)\n",
    "    y_hat = medfilt(y_hat, kernel_size=7)\n",
    "    # NOTE condition some cases of model evaluation\n",
    "    try:\n",
    "        f1s = f1_score(y[test], y_hat, average='weighted', labels=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "    except:\n",
    "        f1s = 0\n",
    "    try:\n",
    "        conf = confusion_matrix(y[test], y_hat, labels=[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "        acc = F.accuracy(conf) # similar to f1 micro\n",
    "    except:\n",
    "        acc = 0\n",
    "    try:\n",
    "        acc_adj = F.accuracy_adjacent(conf, adjacent_facies)\n",
    "    except:\n",
    "        acc_adj = 0\n",
    "    f1s_ls += [f1s]\n",
    "    acc_ls += [acc]\n",
    "    adj_ls += [acc_adj]\n",
    "    print('{:>20s} f1_weigthted:{:.3f} | acc:{:.3f} | acc_adj:{:.3f}'.format(well_name, f1s, acc, acc_adj))\n",
    "# NOTE print the average for 9 well-logs\n",
    "t1 = tm.time()\n",
    "print('Avg F1', np.average(f1s_ls)*100,\n",
    "      'Avg Acc', np.average(acc_ls)*100,\n",
    "      'Avg Adj', np.average(adj_ls)*100)\n",
    "print('Blind Well Test Run Time:', '{:f}'.format((t1-t0)), 'seconds')\n",
    "\n",
    "'''\n",
    "step 5: statified K-fold. This step ensures that the splitting data do not significantly enhance or minimize the inference.  \n",
    "'''\n",
    "\n",
    "X_train = X_scaled\n",
    "Y_train = np_utils.to_categorical(y, classes)\n",
    "t2 = tm.time()\n",
    "estimator = KerasClassifier(build_fn=F.DNN, nb_epoch=15, batch_size=5, verbose=0)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results_dnn = cross_val_score(estimator, X_train, Y_train, cv= skf.get_n_splits(X_train, Y_train))\n",
    "print (results_dnn)\n",
    "t3 = tm.time()\n",
    "print('Cross Validation Run Time:', '{:f}'.format((t3-t2)), 'seconds')\n",
    "\n",
    "'''\n",
    "step 6: use all well-logs for traning and validation.\n",
    "'''\n",
    "\n",
    "NN = F.DNN()\n",
    "NN.fit(X_train, Y_train, epochs=15, batch_size=5, verbose=0)\n",
    "\n",
    "y_predicted = np.argmax(NN.predict(X_train), axis=-1)\n",
    "y_predicted = medfilt(y_predicted, kernel_size=7)\n",
    "\n",
    "f1s = f1_score(y, y_predicted, average='weighted')\n",
    "Avgf1s = np.average(f1s_ls)*100\n",
    "print ('f1 training error: ', '{:f}'.format(f1s))\n",
    "print ('f1 test error: ', '{:f}'.format(Avgf1s))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
